
# Results


```{r,include=FALSE}
library(dplyr)
library(ggplot2)
library(tidyverse)
library(caret)
library(randomForest)
library(glmnet)
library(pROC)
library(stringr)
library(mlbench)
library(gridExtra)
library(arm)
library(formattable)
library(readr)

# Read in both datasets for my project
players <- read_csv("Seasons_Stats.csv")
all_nba <- read_csv("All.NBA.1984-2018.csv", skip = 1)

```

```{r,include=FALSE}
# Recode season to year 
# (eg: recode 1987-1988 season to be year 1988, which is consistent with players dataset)
all_nba$Year <- as.numeric(str_extract(all_nba$Season,"^\\d*"))+1

```

```{r,include=FALSE}
# Filter out season before 2000
players <- players |> filter(Year >= 2000)
all_nba <- all_nba |> filter(Year >= 2000)

```

```{r,include=FALSE}
# Check for NAs with regard to the metric of PER, which stands for Player Efficiency Rating
colSums(is.na(players))["PER"]
index_no_PER <- which(is.na(players$PER))
index_no_PER

```

```{r,include=FALSE}
# Players with index number 3312 3629 4592 5562 7450 do not have PER values
# Remove them
players <- players[-c(3312, 3629, 4592, 5562, 7450),]

```

```{r,include=FALSE}
# Fixing weird team names in the all_nba tibble
# TOT stands for "total" instead of a specific team name because these players, 
# despite selected in the all-NBA teams, were traded during in the middle of that season. 
TOT_all_nba_Player <- all_nba |> filter(Tm == "TOT") |> pull("Player")
TOT_all_nba_Year <- all_nba |> filter(Tm == "TOT") |> pull("Year")

```


```{r,include=FALSE}
# Assign an actual team to that player according to the teams 
# that they played the majority of their games for within that season

# For Chauncey Billups:
CB_team <- players|>filter(Player==TOT_all_nba_Player[1]&Year==TOT_all_nba_Year[1])|>arrange(-G) 
CB_team_name <- CB_team[2,6]

# Substitute Chauncey Billups' team for 2009 season from TOT to DEN
all_nba[which(all_nba$Tm == "TOT")[1],5] <- CB_team_name

# For Dikembe Mutombo:
DM_team <- players|>filter(Player=="Dikembe Mutombo*"&Year==TOT_all_nba_Year[2])|>arrange(-G)
DM_team_name <- DM_team[2,6]

# Substitute Dikembe Mutombos' team for 2009 season from TOT to ATL
all_nba[which(all_nba$Tm == "TOT")[1],5] <- DM_team_name

```


```{r,include=FALSE}
# Remove the column that's entirely blank
players$blank2 <- NULL
players$blanl <- NULL

```


```{r,include=FALSE}
# Recode column names so that they don't start with a number/end with a "%" sign,
# which would make it hard to call the column name.
players <- players |> rename("X3P" = "3P",
                  "X3PA" = "3PA",
                  "X3P." = "3P%",
                  "X2P" = "2P",
                  "X2PA" = "2PA",
                  "X2P." = "2P%",
                  "X3PAr" = "3PAr",
                  "TS." = "TS%",
                  "X3PAr" = "3PAr",
                  "ORB." = "ORB%",
                  "DRB." = "DRB%",
                  "TRB." = "TRB%",
                  "AST." = "AST%",
                  "STL." = "STL%",
                  "BLK." = "BLK%",
                  "TOV." = "TOV%",
                  "USG." = "USG%",
                  "WS.48" = "WS/48",
                  "FG." = "FG%",
                  "eFG." = "eFG%",
                  "FT." = "FT%"
                  )

```


```{r,include=FALSE}
# Change Player stats to per game instead of for the whole season to make it fair;
# Also change the variables' names to be more interpretable
players_pergame <- players |> mutate(Name = Player,
                                     Position = Pos,
                                     age = Age,
                                     year = Year,
                                     Team = Tm,
                                     Games = G,
                                     Starts = GS,
                                     Minutes = MP/G,
                                     Points = PTS/G,
                                     Rebounds = TRB/G,
                                     Assists = AST/G,
                                     Steals = STL/G,
                                     Blocks = BLK/G,
                                     Turnovers = TOV/G,
                                     Fouls = PF/G,
                                     FTs = FT/G,
                                     Threes = X3P/G,
                                     FGs = FG/G,
                                     Usage = USG.,
                                     EfficiencyRating = PER,
                                     BoxPlusMinus = BPM,
                                     ShootingPercentage = eFG.)

# Extract the 22 columns that we just created
players_pergame <- players_pergame[,c(52:73)]

```


```{r,include=FALSE}
# Exclude bench players that would've never made to the All-NBA teams anyway
# The number 12 is chosen for Minutes because each quarter is 12 minutes.
# The number 10 is chosen for Games because usually really good teams would rest
# their starting players for the last 10 or so regular season games and play more
# bench warmers that never got a chance to play during the first 72 games 
# in order to protect their starting players from getting an injury before play-off starts.

players_pergame <- players_pergame |> filter(Minutes >= 12 & Games >= 10)

```


```{r,include=FALSE}
# Remove "*" at the end of some players' names
for(i in 1:nrow(players_pergame)){
  if (str_detect(players_pergame$Name[i],"\\*")){
    players_pergame$Name[i] <- str_sub(players_pergame$Name[i],1,-2)
  }
}

```


```{r,include=FALSE}
# Fixing the issue of inconsistency for Metta World Peace's name
players_pergame<-players_pergame|>mutate(Name=case_when(Name=="Metta World"~"Metta World Peace",
                                                              TRUE ~ Name))

# Create matching labels in two datasets
players_pergame <- players_pergame |> mutate(Name_year = paste(Name,year))
all_nba <- all_nba |> mutate (Player_Year = paste(Player, Year))

# Create labels for these players: All_NBA = 1/0
players_pergame <-players_pergame|>mutate(All_NBA=case_when(Name_year %in% all_nba$Player_Year ~ 1,
                                                ! Name_year %in% all_nba$Player_Year ~ 0))

```



## Logistic Regression

First, I decided to further remove some variables that are not important for our analysis, such as names, positions, teams and etc.

```{r,include=FALSE}
# Remove variables that are not important in our analysis, 
# such as names, positions, teams and etc.
players_pergame_model <- players_pergame[,-c(1,2,4,5,23)]

# Add a new variable called start., which is calculated by the number of games that player started
# divided by the number of games that player played. 
# Also, move the variable All_NBA, which is our label, to the last column.
players_pergame_model<-players_pergame_model|>mutate(Start.=Starts/Games)|>
  relocate(All_NBA,.after=last_col())

# Now, we can remove the column "Starts" so that these columns won't be associated with each other
# (since the presence of Games, Starts, and Start. at the same time may lead to convergent issues)
players_pergame_model <- players_pergame_model[,-3]

```


The next step was to split the whole dataset into training set and test set. I chose to reserve 25% of the data for our test set since I wanted to make sure that there are enough All-NBA players in the test set for model evaluation. Subsequently, I trained the logistic regression model along with a **5-fold cross validation** and evaluated the model on the test set using a confusion matrix. 


```{r,include=FALSE}
# Train-test split
set.seed(2022)
y <- players_pergame_model$All_NBA

test_index <- createDataPartition(y, times = 1, p = 0.75, list = FALSE)
test_set <- players_pergame_model |> slice(-test_index)
train_set <- players_pergame_model |> slice(test_index)

```


Below is the confusion matrix table that demonstrates the performance of our logistic regression model on the test set. As shown below, we obtained an overall accuracy of 98.34%, which seems to be pretty decent. However, we also obtained a low specificity since we only predicted 44 players to make the All-NBA team out of the 66 players who actually made the All-NBA teams in the test set.

```{r,echo=FALSE,warning = FALSE}
# Set up train control details for cross validation
control_lg <- trainControl(method="cv", number=5)

# Train the model using the train() function
model_lg <- train(All_NBA~., data=train_set, method="glm", family = "binomial", trControl=control_lg)

# Evaluate the model on test set using a Confusion Matrix
p_hat_glm <- predict(model_lg, test_set)
y_hat_glm <- ifelse(p_hat_glm >= 0.5, 1, 0) 
y_hat_glm_factor <- factor(y_hat_glm)
confusionMatrix(y_hat_glm_factor, as.factor(test_set$All_NBA), mode = "everything")

```

The AUC score of our model is also calculated and shown below:

```{r,echo=FALSE,message = FALSE}
# Get AUC Score
auc(test_set$All_NBA,y_hat_glm)

```


I also plotted the ROC curve for the logistic regression model below:

```{r,echo=FALSE,message = FALSE}
# Plot ROC curve
roc_score = roc(test_set$All_NBA, y_hat_glm) 
plot(roc_score, main ="ROC Curve - Logistic Regression")

```


To determine which features of the players play important roles in determining the All-NBA team selection, I also calculated variables' importance and plotted the results below:

```{r,echo=FALSE,warning = FALSE}
# Demonstrate feature importance
importance <- varImp(model_lg, scale=FALSE)

# print(importance) 
# The output of the above command is eventually not shown because I think the plot below
# is more straightforward

# plot importance
plot(importance,main = "Feature Importance from Logistic Regression model")

```

According to the plot above, we can see that some of the features that are more indicative of All-NBA selections are *Games* (i.e. The number of games played in that season), *ShootingPercentage* (i.e. Effective Field Goal Percentage; a.k.a eFG%), and *BoxPlusMinus* (i.e. Box Plus/Minus, which is a box score estimate of the points per 100 possessions that a player contributed above a league-average player, translated to an average team)$^{1}$. From my perspective, these top-3 most important features make sense to me in that the general public usually regards players with high Box Plus/Minus and players who have high field goal percentages good players; and as a result, good players usually gets to play more games.

To sum up, after training a logistic regression model with 5-fold cross validation, we obtained a model with an overall accuracy of 98.34%, and the 3 most important features indicated by this model are *Games*, *ShootingPercentage*, and *BoxPlusMinus*.


## Random Forest

```{r,include=FALSE}
set.seed(2022)
control <- trainControl(method="cv", number=5)

# Testing out the parameter of mtry from 1 to 10
tunegrid <- expand.grid(.mtry=c(1:10))
rf_cv <- train(as.factor(All_NBA)~., data=train_set, method="rf",
               metric="Accuracy", tuneGrid=tunegrid, trControl=control)

```


I also applied a **5-fold cross validation** to help train the model while tuning the parameter *mtry* of my random forest model. I tried out values from 1 to 10 for *mtry* and reported the results in the table below (FYI: the best value used for *mtry* is shown at the last line of the output below):


```{r,echo=FALSE}
print(rf_cv)

```


Below is a visual demonstration of how the accuracy of this model changes with the value of *mtry*:


```{r,echo=FALSE}
plot_1 <- rf_cv |> ggplot(aes(rf_cv$results$mtry,rf_cv$results$Accuracy))+
  geom_line(col="blue")+
  xlab("mtry")+
  ggtitle("Parameter tuning for \"mtry\" based on model accuracy")+
  theme_bw()

plot_1

```

Below is the confusion matrix table that demonstrates the performance of our random forest model on the test set. We obtained an overall accuracy of 98.28%, which also seems to be pretty decent. However, we did have a low specificity since we only predicted 44 players to make the All-NBA team out of the 66 players who actually made the All-NBA teams in the test set. 


```{r,echo=FALSE}
p_hat_rf <- predict(rf_cv, test_set)
confusionMatrix(p_hat_rf, as.factor(test_set$All_NBA), mode = "everything")

```

The AUC score of our model is also calculated and shown below:

```{r,echo=FALSE,message = FALSE}
# Get AUC Score
y_hat_rf <- ifelse(p_hat_rf == "1", 1, 0) 
y_hat_rf_factor <- factor(y_hat_rf)
auc(test_set$All_NBA,y_hat_rf)

```


I also plotted the ROC curve for the random forest model below:

```{r,echo=FALSE,message = FALSE}
# Plot ROC curve
roc_score_rf = roc(test_set$All_NBA, y_hat_rf) 
plot(roc_score_rf, main ="ROC Curve - Random Forest")

```


```{r,include=FALSE}
set.seed(2022)
RFmodel <- randomForest(as.factor(All_NBA) ~ ., data = train_set, mtry=rf_cv$bestTune$mtry)

```


To determine which features of the players play important roles in determining the All-NBA teams selection, I also calculated variables' importance and plotted the results below:


```{r,echo=FALSE}
varImpPlot(RFmodel, main = "Feature Importance from Random Forest model")

```

According to the plot above, we can see that some of the features that are more indicative of All-NBA selections are *EfficiencyRating* (i.e. Player Efficiency Rating, which sums up a player's positive accomplishments, subtracts the negative accomplishments, and returns a per-minute rating of a player's performance; a.k.a PER), *BoxPLusMinus* (i.e. Box Plus/Minus, which is a box score estimate of the points per 100 possessions that a player contributed above a league-average player, translated to an average team), and *Points* (i.e. The average amount of points the player scores per game in that season)$^{1}$. From my perspective, these top-3 most important features also make sense to me in that the general public usually regards players with high Box Plus/Minus, high player efficiency rating (high PER values), and high scoring capabilities good players.


To sum up, after training a random forest model with 5-fold cross validation, we obtained a model with an overall accuracy of 98.28%, and the 3 most important features indicated by this model are *EfficiencyRating*, *BoxPlusMinus*, and *Points*.

